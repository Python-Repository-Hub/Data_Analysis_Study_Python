{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **03.유저 Funnel 분석을 통해 이탈 구간 개선**\r\n",
    "--------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **목적**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### Funnel 분석의 개념을 이해하고 로그 데이터를 통해 분석 실습을 진행한다.\r\n",
    "* ### 마치 분석 프로젝트 업무를 맡은 담당자라 생각하고 2강 내용을 학습한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **목차**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 배경, 문제 정의 및 가설 정립\r\n",
    "* ### 분석 Frame 구성\r\n",
    "* ### 데이터 전처리\r\n",
    "* ### 데이터 분석\r\n",
    "* ### 리포트 작성"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **03-1. 문제 정의 및 가설 설정**\r\n",
    "--------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 여러분이 데이터 분석가로서 회사에 새로 입사했다고 가정해보자. 경력직으로서 여러분이 처음 맡은 업무는 기획팀에서 요청한 업무로, 미팅을 통해 아래와 같은 요청을 받았다고 해보자"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **요청내용**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### \"(기획안을 주면서) 새로운 시나리오를 유저가 잘 사용하고 있는지 알려주세요.\"\r\n",
    "* ### \"잘 사용되고 있는 기능은 무엇인지 알려주세요.\"\r\n",
    "* ### \"개선을 어떻게 해야할지 알려주세요\"\r\n",
    "* ### \"언제까지 결과를 받아볼 수 있을까요? 담당자는요?\"\r\n",
    "* ### \"데이터가 있는지 모르겠어요. 없으면 수집해주세요.\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 대략 정리를 해보면,\r\n",
    "\r\n",
    "### 기획부서에서 만든 새로운 시나리오 대로 유저가 앱을 잘 사용하고 있는지, 만약 그렇다면 어떤 기능이 잘 사용되고, 이탈이 많다면 어느 구간인지 어떻게 그 구간을 개선할지 알려달라는 요청을 받았다고 할수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **배경**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 문제의 배경은 보통 분석을 요청하는 외부의 팀(예, 기획, 마케팅 등)에 의해 발의되고, 여러 번의 논의를 통해 이루어진다. 논의가 마무리된 후 간단하게 배경과 목적 등을 정리하여 공유 및 최종 컨펌을 받아 놓는 것은 유용하다. 이번 가상 사례의 경우, 아래와 같이 배경이 정리될 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 유저가 남긴 데이터를 기반으로 신규 시나리오에 대한 사용성을 파악하고 개선점을 도출\r\n",
    "* ### 궁극적인 목적은 유저 피드백을 통한 Learning을 통해 전반적인 사용자 경험(UX)를 지속적으로 높이는 것"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\16.png \"16_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **문제 정의**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 문제를 정확하게 정의하고 목적을 설정하는 과정은 모든 분석 프로젝트 과정에서 가장 중요한 과정이라고 해도 과언이 아니다. 배경을 통해 문제를 정의하면 아래와 같이 정리할 수 있다. 만약 실무에서 모호한 부분이 있다면, 분석 요청자와 충분한 논의를 거쳐 이 단계를 보다 명확하게 진행하고 다음 단계로 넘어가는 것이 중요하다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### Funnel 방식으로 유저의 행동 패턴을 파악하여 해당 시나리오의 Bottleneck 구간을 탐색하자\r\n",
    "* ### 유저를 세분화하여 Bottleneck 개선 방안에 유용한 Insight를 도출하자"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **가설 정립 및 예상 Output**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 가설을 설정하는 것은 도메인 지식이 충분하지 않거나 분석 업무 경험이 많지 않다면 어려울 수 있는 부분이다. 가설 설정은 상황에 따라 생략할 수 있는 부분이며, 오히려 데이터 탐색의 범위를 좁히는 결과를 낳기도 하기 때문에 목적 설정 과정에 비해 중요도가 높지 않다고 할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 그러나 가설을 만들고 예상 산출물(Output)을 그려보는 과정은 데이터 수집 및 분석 과정에서 수많은 의사결정을 진행할시 도움이 되기도 한다. 이번 가상 상황에서는 아래와 같이 가설을 미리 도출하여 예상 산출물을 어렴풋이 그려볼 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 가설1: 이탈이 많이 발생하는 구간은 구매 상세 페이지에서 구매 완료로 전환하는 구간일 것이다.(Bottleneck)\r\n",
    "> * #### 이유1: 구매를 한다는 것은 돈을 지불해야 하는 행위이며 일반적으로 목적 달성이 어려움\r\n",
    "* ### 가설2: 그룹 조건에 따라 전환율이나 이탈율에서 통계적으로 유의미한 차이를 보일 것이다.\r\n",
    "> * #### 이유2: 그룹 조건은 행동 패턴을 결정짓는 주요 요인중 하나이므로 위와 같은 결과가 나올 것. (단, 그룹 세분화가 진행되기 전이므로 다소 오픈 결론으로 유지)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\17.png \"17_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **03-2. 분석 프레임**\r\n",
    "--------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **MECE**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 분석 Frame은 최종 목표를 달성하기 위한 나침반 혹은 지도와 같은 역할을 한다. 보통 Frame은 최상위 목적, 그리고 그 목적을 달성하기 위한 하위 목적, 그리고 세부적인 Task로 구성이 된다. 이러한 구성을 위해 목표와 Task를 잘 구분하고 분류하는 것이 중요한데, 이 과정에 많이 쓰이는 철학과 접근법이 MECE이다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MECE는 Mutually Exclusive Collectively Exhaustive의 약자로, 항목을 겹치지 않고 누락되지 않게 잘 나눈 것이라고 할 수 있다. 특히 비즈니스 목적이나 데이터 분석의 목적을 달성하기 위한 Frame을 구성할 때 유용하게 사용할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\18.png \"18_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **서비스 건강도에 대한 MECE 접근법 예시**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 예를 들어, 특정 서비스의 건강도를 측정하는 지표를 계획한다고 가정해보자. 서비스 건강도를 일별 방문자수, 재방문율, 구매율 및 재구매율 등으로 서로 독립적인 하위 지표로 구성할 수 있으며(ME), 누락없이(CE) 측정할 수 있을 것이다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### **서비스 건강도**\r\n",
    "> * ### 방문자수\r\n",
    ">> * #### 재방문자수 및 재방문율\r\n",
    ">> * #### 신규방문자수\r\n",
    "> * ### 이용자수\r\n",
    ">> * #### 특정 기능 이용자수\r\n",
    ">>> * #### 신규유저\r\n",
    ">>> * #### 기존유저\r\n",
    ">> * #### 특정 기능 재이용자수 (재이용율)\r\n",
    ">>> * #### 신규유저\r\n",
    ">>> * #### 기존유저\r\n",
    "> * ### 구매자수\r\n",
    ">> * #### 재구매자 및 재구매율\r\n",
    ">> * #### 신규구매자 및 구매전환율\r\n",
    ">> * #### ARPU, ARPPU, LTV\r\n",
    "> * ### 추천(공유)수\r\n",
    ">> * #### 추천 제공자수\r\n",
    ">> * #### 추천으로 인해 유입된 유저수"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **타당도와 신뢰도**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 많은 논의를 통해 서로 독립적이며 누락없는 하위 지표를 구성한후 그 지표가 건강도를 잘 대표하고 있는지(타당도), 시간의 흐름에 관계 없이 Robust한 결과를 보이는지(신뢰도) 등 종합적으로 고려하여 지표를 설정하고 Tracking 하는 것은 분석 Frame 설정의 한 예시이다.\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 측정하고자 하는 지표를 타당한 방식으로 측정하고 있는가?\r\n",
    "    * ### Benchmark 지표는?\r\n",
    "    * ###  Benchmark와 상관관계는?\r\n",
    "* ### 시간의 흐름에 상관없이 일관적인 결과를 보이는가?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Logic Tree**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 이번엔 Logic Tree에 대해 알아보자. Logic Tree 모습은 마치 머신러닝 기법인 Decision Tree의 유사하다. 최종 목적을 세부적인 목적으로 분류하는 데 도움을 주는 방법론이다. 상위 단계에서 하위 단계로 구분되어 내려갈 때 MECE 철학에 근거해 잘게 쪼개질 때까지 진행하는 것이 중요하다. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\19.png \"19_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 지금까지 배운 MECE와 Logic Tree를 이용해, 유저 사용성 분석의 목적에 맞는 분석 Frame을 작성/실습해보자. 아래 예제를 참고하여 파워포인트나 키노트, 혹은 메모장 등 프로그램을 실행시켜 최종 목적부터 세부적인 목적까지 직접 작성해보고 Feedback을 구해보자. 반드시 박스와 선을 이용할 필요는 없으며 방향도 위에서 아래로 내려가도 무방하다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\20.png \"20_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 다른 분석/주제 예시\r\n",
    "    * ### 마케팅 프로모션/이벤트 타깃팅\r\n",
    "    * ### 브랜드 위상/이미지 측정 및 제고\r\n",
    "    * ### 개인화 컨텐츠/서비스 (Recommendation System)\r\n",
    "    * ### 매출/유료 결제자 상승 예측 모델링/타깃팅\r\n",
    "    * ### 어뷰징 사례 예측/분류 모델링\r\n",
    "    * ### 텍스트 분석/토픽 모델링\r\n",
    "    * ### 신규 지표 개발"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **추가 고려 요소**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터가 입수되고 앞에서 살펴본 문제 정의, 가설 설정 및 분석 Frame 단계를 완료하였다면 분석 준비가 완료되었다고 볼 수 있다. 다만, 실무에서는 추가로 고려해야할 사항이 더 있다. 주로 Management와 관련된 부분으로, PM 혹은 Team Manager, 분석 요청자와 아래와 같은 사항을 논의할 필요가 있다. 이미 언급한 대로, 분석 프로젝트는 분석가 혹은 분석팀 자체적으로 진행되는 경우가 없으므로 프로젝트를 둘러싼 외부적 상황에 따라 크게 영향 받기도 한다. 따라서 아래와 같은 고려 사항을 소홀히하지 않도록 해야 불필요한 리소스 낭비를 최소화할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 일정 (중간 단계별 공유, 최종 Ouput 발표, 공유 방식 등)\r\n",
    "* ### Project/Task 우선순위 (동 기간 타 프로젝트가 있을 경우, 우선순위 조정)\r\n",
    "* ### 유관팀 사전 논의 및 데이터 엔지니어 지정 (Co-workers)\r\n",
    "* ### 필요 Resource (소프트웨어, 서버 등)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[실습파일](https://github.com/songhunhwa/songhunhwa.github.com/tree/master/tutorial/tutorial_02 \"퍼널분석 실습파일\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **03-3. 데이터 전처리**\r\n",
    "--------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 목적을 정의했고 가설 정립 및 분석 Frame 단계를 마쳤다면, 실제 데이터를 수집/추출하여 분석 단계를 준비하는 데이터 전처리 단계를 진행한다. 수집/추출 단계는 데이터 엔지니어의 역할이 크고, 또 이 수업의 범위를 벗어난 내용이므로 생략한다. 단, 이러한 수집/추출 과정에서 무엇을 수집할지 그리고 데이터의 Quality를 파악하는 것은 분석가가 관여하는 부분임을 인지할 필요가 있다. 일반적으로 아래와 같은 이유로 바로 실제 분석을 하기 전, 데이터 전처리 단계를 반드시 거쳐야 한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 여러 데이터 소스 활용: 테이블 스키마나 Label, Type 등이 상이하여, 분석을 위해 일관적인 방식으로 통합/변환 필요\r\n",
    "* ### 데이터 기록/수집의 누락 및 오류 (Missing Value, Errors, typo 발생)\r\n",
    "* ### 자연스러운 혹은 기계적으로 발생하는 이상치 or 극단치\r\n",
    "* ### 분석 목적에 맞지 않은 변수 혹은 분포"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\21.png \"21_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **데이터 전처리 가이드**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 위에 나열된 내용 이외에도 예상하지 못한 이유로 인해 결측치 및 이상치 등이 쉽게 발생할 수 있으며, 이러한 문제가 있는 데이터를 전처리하지 않고 분석 혹은 모델링 등의 업무를 진행할 경우 치명적인 문제/오류를 발생시킬 수 있으므로 매우 주의할 필요가 있다. 일반적으로 각 문제점별 데이터 전처리를 하는 방식은 아래와 같다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 데이터 Type, Label 등이 일관적이지 않은 경우\r\n",
    "    * ### 프로그램에서 제공하는 함수를 통해 일괄적으로 변경 (예, SQL: Cast, Python: astype())\r\n",
    "* ### Missing Value\r\n",
    "    * ### 수치형인 경우 Mean, Median 등 대푯값으로 채우거나 실수 예측 모델링 활용 (예, Linear Regression)\r\n",
    "    * ### 카테고리형인 경우 Mode로 채우거나 분류 예측 모델링 활용 (예, Logistic Regression)\r\n",
    "* ### Errors, Typo 발생의 경우\r\n",
    "    * ### 텍스트 처리 함수 활용 (예, Python: str.replace())\r\n",
    "* ### 이상치(outlier)\r\n",
    "    * ### IQR, Z-score, MAD 등 방식으로 이상치 제거\r\n",
    "* ### 변수가 많은 경우(20개 이상)\r\n",
    "    * ### PCA 등으로 차원 축소하거나 변수 중요도 파악후 불필요 변수 제거\r\n",
    "* ### 편향된 분포의 변수가 존재하는 경우\r\n",
    "    * ### log, sqrt 등 함수로 분포 변환\r\n",
    "* ### 측정 단위(scale)이 차이가 클 경우\r\n",
    "    * ### StarndardScale or MinMaxScaler 통해 스케일링"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **전처리 내용**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 이번 전처리 내용은 비교적 간단한 편이며, 전처리 진행 과정은 아래와 같다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **날짜를 pandas datetime 형태로 변환**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "## 날짜가 String인 경우 \r\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\r\n",
    "pd.Series(pd.to_datetime(['2005/11/23', '2010.12.31', '2011.1.1']))\r\n",
    "\r\n",
    "## 날짜가 timestamp인 경우\r\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\r\n",
    "pd.Series(pd.to_datetime([1349720105, 1349806505, 1349892905, 1349979305, 1350065705], unit='s'))#.dt.date\r\n",
    "\r\n",
    "## 컬럼 타입을 바꾸는 경우\r\n",
    "df1['datetime'] = df1['datetime'].astype('datetime64[ns]')\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **결측치 처리**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 경우에 따라 결측치 처리 방법이 달라진다. 만약 샘플수가 많다면 missing values 를 포함하는 행을 모두 삭제하는 것이 가능하다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "# 결측치가 하나라도 있으면 버리는 코드 예제\r\n",
    "df.dropna()\r\n",
    "\r\n",
    "# 모든 값이 Null일 경우만 버리는 코드 예제\r\n",
    "df.dropna(how='all')\r\n",
    "\r\n",
    "# 결측치가 하나 이상 있는 Case만 선택하는 코드 예제\r\n",
    "df[df.isnull().any(axis=1)]\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 만약 샘플수가 충분하지 않을 경우, Pandas의 fillna() 명령어로 Null 값을 채우는 것이 가능하다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 연속형인 경우 Mean이나 Median 등 대푯값 이용\r\n",
    "* ### 명목형인 경우 Mode(최빈치)나 예측 모형을 통해 Null 값 대체"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 경우에 따라 도메인 지식을 이용해 결측치를 처리하거나, 회귀 및 분류 예측모델을 이용하는 경우도 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "# Null 값을 median으로 대체하는 코드 예제\r\n",
    "df.fillna(df.mean()) \r\n",
    "\r\n",
    "# Null 값을 mode로 대체하는 코드 예제\r\n",
    "freq_values = df_ms.documentposition.value_counts().index[0]\r\n",
    "df['col1'] = df['col1'].fillna(freq_values)\r\n",
    "\r\n",
    "# Null 값을 KNN predictive model을 이용해 처리하는 예제\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_ind, df_tar, random_state=0)\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\r\n",
    "fill_values = knn.predict(df[ind_cols].apply(lambda x: encoder.fit_transform(x)))\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **텍스트 통일**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 같은 의미를 지니는 텍스트이나 다른 카테고리 값으로 수집된 경우, 해당 카테고리의 값을 동일하게 맞춰줄 필요가 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### dict 형태로 기존 값과 변경 값을 저장\r\n",
    "* ### replace 명령어을 통해 일괄적으로 변경"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "# dict 생성\r\n",
    "ext_dic = {'DOCX': 'DOC',\r\n",
    "           'XLSX': 'XLS',\r\n",
    "           'PPTX': 'PPT',\r\n",
    "           'PPSX': 'PPT',\r\n",
    "           'PPS': 'PPT',\r\n",
    "           'ODT': 'TXT',\r\n",
    "           'PNG': 'JPG'}\r\n",
    "\r\n",
    "# 해당 컬럼에 replace 함수와 dict 적용\r\n",
    "df['ext'] = df['ext'].replace(ext_dic)\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **신규id 부여**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ID 와 같이 유니크 식별자의 경우, 기계적으로 부여되므로 알아보기 어려울 뿐만 아니라 데이터 사이즈를 키우는 원인이 된다. 이를 간단하게 변경해서 처리해야 할 경우가 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 빈 리스트 생성\r\n",
    "* ### ID 컬럼의 행 별로 동일 여부 비교\r\n",
    "* ### 만약 전행과 후행이 동일하다면 동일한 값을 부여, 아닐 경우 +1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "s = [] # empty list\r\n",
    "j = 0 # default setting\r\n",
    "\r\n",
    "# loop\r\n",
    "for i in range(len(df)-1):\r\n",
    "\r\n",
    "    # compare each rows\r\n",
    "    if df.ix[i, 'sessionid'] == df.ix[i+1, 'sessionid']:\r\n",
    "        s.append(j)\r\n",
    "\r\n",
    "    # update j values\r\n",
    "    else:\r\n",
    "        s.append(j)\r\n",
    "        j += 1\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **대소문자 처리**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 필수는 아니지만, 모든 텍스트가 소문자일 경우 대소문자 여부가 중요하지 않게 된다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 타이핑시 대소문자 변환 불필요\r\n",
    "* ### 오탈자 문제 방지\r\n",
    "* ### 생산성 증대 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "cols = df.columns # list of columns' names\r\n",
    "\r\n",
    "# loop\r\n",
    "for c in cols:\r\n",
    "    if c != 'datetime':  \r\n",
    "        df[c] = df[c].apply(lambda x: x.lower())\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[실습파일](https://github.com/songhunhwa/songhunhwa.github.com/tree/master/tutorial/tutorial_02 \"데이터 전처리\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **03-4. 데이터 분석**\r\n",
    "--------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 전처리 과정이 완료되면 데이터 분석 과정을 진행한다. 데이터 분석은 매우 넓은 범위를 포괄하는데, 일반적으로 EDA라고 불리는 탐색적 데이터 분석을 위해 전통적인 통계 분석, 기계학습(Feature Engineering), 시각화 기법 등 다양한 방식이 활용되며 단순한 EDA를 끝으로 업무/프로젝트가 완료되는 경우도 많다.\r\n",
    "\r\n",
    "### EDA는 분석가가 데이터를 이해하고 모델링을 잘 하기 위한 필수적인 과정이다. 간혹 EDA 과정을 통한 충분한 이해와 Feature selection 없이 모델링을 바로 진행하는 경우가 있는데, 성능이 안 좋은 모델이 구축되거나 성능 개선에 많은 시간이 소요되므로 지양해야 한다.\r\n",
    "\r\n",
    "### 이번 가상 케이스의 경우 EDA만을 통해 원하는 목적을 달성할 수 있으므로 EDA를 끝으로 분석 업무가 마무리 될 예정이다. 보통 이 단계쯤에서는 목적을 다시 한번 상기하는 것이 도움이 될 수 있다. 초반에 설정한 목적을 확인하고 아래 과정을 실습해보자."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **일별 주요 통계**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 일별로 주요 지표의 흐름을 보는 것은 특정 패턴을 발견하는 데 유용하다. 특정 주나 월, 요일별로 데이터 패턴을 보거나 주요 화면의 빈도를 구함으로써 앱의 사용성 패턴에 대해 감을 잡을 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 일별, 요일별 데이터 빈도 및 증감 패턴\r\n",
    "* ### 시간 변수와 다른 카테고리별 변수(피벗)의 상호작용"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "# 일별 데이터 카운트 예제\r\n",
    "df.groupby(\"datetime\").size()\r\n",
    "\r\n",
    "# 요일별 유니크 세션수 카운트 및 시각화 예제\r\n",
    "s = df.groupby(\"datetime\")['sessionid'].nunique()\r\n",
    "s.index = s.index.dayofweek\r\n",
    "\r\n",
    "s.plot(color='grey', kind='bar', rot=0);\r\n",
    "plt.title(\"Daily Session\")\r\n",
    "plt.tight_layout()\r\n",
    "``` "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\22.png \"22_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "# 일별, 카테고리별 카운트 (피벗팅)\r\n",
    "df.groupby([\"datetime\", \"ext\"]).size().unstack().dropna(axis=1)\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\23.png \"23_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "# 일별 화면별 카운트 및 히트맵 시각화 예제\r\n",
    "screens = df.groupby([\"datetime\", \"screen\"])['sessionid'].nunique().unstack().fillna(0).astype(int)\r\n",
    "screens = screens[screens.mean().sort_values(ascending=False).index]\r\n",
    "\r\n",
    "plt.subplots(figsize=(17,8))\r\n",
    "sns.heatmap(screens, annot=True, fmt=\"d\", annot_kws={\"size\": 15}); # we can do the same via Excel\r\n",
    "\r\n",
    "plt.title(\"screen count daily\")\r\n",
    "plt.tight_layout()\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\24.png \"24_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **변수별 특성(분포, 상관관계)**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 변수에 대한 이해를 위해 많이 사용되는 시각화 기법이 Scatter Matrix 이다. 변수별 히스토그램과 변수가 Scatter Plot을 동시에 보여주기 때문에 한눈에 데이터 특성을 파악하기 용이하다. 이외 Box-plot, Bar Plot 등 다양한 시각화 기법이 이용된다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### Histogram\r\n",
    "* ### Scatter Plot\r\n",
    "* ### Box Plot\r\n",
    "* ### Bar Plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "# Scatter Matrix 를 통해 분포 및 변수간 상관관계 시각화 예제\r\n",
    "from pandas.tools.plotting import scatter_matrix\r\n",
    "\r\n",
    "scatter_matrix(df_by_user, figsize=(10, 10));\r\n",
    "plt.tight_layout()\r\n",
    "\r\n",
    "#  상관지수 확인\r\n",
    "df_by_user.corr()\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\25.png \"25_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **구간별 전환율**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 전환율을 구하기 위한 수식은 간단하다. 분자 / 분모 * 100 수식을 이용해 간단히 전환%를 산출할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 주요 구간 설정\r\n",
    "* ### 전환율 수식 적용"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "# 구간별 전환수 \r\n",
    "conver_cnt = screens.mean().apply(lambda x: int(x)).sort_values(ascending=False)\r\n",
    "\r\n",
    "# 구간별 전환율 및 시각화 예제\r\n",
    "conver_rt = [conver_cnt[i + 1] / (conver_cnt[i] * 1.0) * 100 for i in range(len(conver_cnt)) if i < 6]\r\n",
    "\r\n",
    "fun_label = [conver_cnt.index[k] + \" -> \" + conver_cnt.index[k + 1] for k, v in enumerate(conver_cnt.index) if k < 6]\r\n",
    "\r\n",
    "pd.Series(conver_rt, index=fun_label).plot(kind='bar', color = 'darkblue', rot=20, figsize=(10,7), fontsize=13)\r\n",
    "\r\n",
    "plt.title(\"Conver Rate\")\r\n",
    "plt.tight_layout()\r\n",
    "\r\n",
    "# 구간별 전환율 및 이탈율 비교 시각화 예제\r\n",
    "conv_rt_tb = pd.Series(conver_rt, index=fun_label).to_frame()\r\n",
    "\r\n",
    "conv_rt_tb.index.name = 'Funnel'\r\n",
    "conv_rt_tb.columns = ['conver_rt']\r\n",
    "conv_rt_tb['churn_rt'] = 100 - conv_rt_tb['conver_rt']\r\n",
    "\r\n",
    "sns.heatmap(conv_rt_tb, annot=True, annot_kws={\"size\": 15});\r\n",
    "plt.tight_layout()\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\26.png \"26_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **클러스터 별 전환율 차이**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 전체 유저를 대상으로 전환율을 구할 경우 큰 Implication 을 얻기 어렵다. 최대한 쪼개서 볼수록 많은 인사이트를 얻을 수 있으며, 유저를 분류할 때 많이 쓰이는 기법이 클러스터링이다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 클러스터링을 위한 주요 변수 설정 (필요시 PCA로 차원 축소)\r\n",
    "* ### K-Means 알고리즘 적용후 그룹핑\r\n",
    "* ### 그룹별 대푯값 및 시각화 등을 통해 탐색\r\n",
    "* ### 여러 요인을 카테고리 단으로 묶는 요인분석(Factor Analysis)과 목적이 다름에 유의"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\r\n",
    "# K-Means 이용한 클러스터링 예제\r\n",
    "from sklearn.cluster import KMeans\r\n",
    "\r\n",
    "df_ext_mat = df_ext.as_matrix()\r\n",
    "km = KMeans(n_clusters = 4).fit(df_ext_mat)\r\n",
    "labels = km.labels_\r\n",
    "\r\n",
    "# group 변수 생성\r\n",
    "df_ext['group'] = labels\r\n",
    "\r\n",
    "# 숫자 to 그룹명 변경\r\n",
    "group_name = {0: 'gr_hwp',\r\n",
    "              1: 'gr_pdf',\r\n",
    "              2: 'gr_xls',\r\n",
    "              3: 'gr_doc'}\r\n",
    "\r\n",
    "df_ext['group'] = df_ext['group'].replace(group_name)\r\n",
    "\r\n",
    "# 그룹별 전환율 함수 생성\r\n",
    "def conv_rt_by_grp(gr):\r\n",
    "    df_gr_screen = df_cluster[df_cluster['group'] == gr]\\\r\n",
    "                     .groupby([\"datetime\", \"screen\"])['sessionid']\\\r\n",
    "                     .nunique().unstack().fillna(0).astype(int)\r\n",
    "\r\n",
    "    conver_cnt = df_gr_screen.mean().apply(lambda x: int(x)).sort_values(ascending=False)\r\n",
    "    conver_rt = [conver_cnt[i + 1] / (conver_cnt[i] * 1.0) * 100 for i in range(len(conver_cnt)) if i < 6]\r\n",
    "    conver_rt = pd.Series(conver_rt, index=fun_label).fillna(0)    \r\n",
    "    return conver_rt\r\n",
    "\r\n",
    "# 그룹별 전환율 산출\r\n",
    "conv_rt_pdf = conv_rt_by_grp('gr_pdf')\r\n",
    "conv_rt_doc = conv_rt_by_grp('gr_doc')\r\n",
    "conv_rt_xls = conv_rt_by_grp('gr_xls')\r\n",
    "conv_rt_hwp = conv_rt_by_grp('gr_hwp')\r\n",
    "\r\n",
    "# 가중치 부여\r\n",
    "weights = [1, 1.3, 1.5, 2, 2.1, 2.2]\r\n",
    "\r\n",
    "def weight_avg(gr):\r\n",
    "    w = (gr.values * weights).sum() / len(gr)\r\n",
    "    return w\r\n",
    "\r\n",
    "# 가중치 함수 적용\r\n",
    "gr_pdf_w = weight_avg(conv_rt_pdf)\r\n",
    "gr_doc_w = weight_avg(conv_rt_doc)\r\n",
    "gr_xls_w = weight_avg(conv_rt_xls)\r\n",
    "gr_hwp_w = weight_avg(conv_rt_hwp)\r\n",
    "\r\n",
    "# 데이터프레임으로 변환\r\n",
    "zip([gr_pdf_avg, gr_doc_avg, gr_xls_avg, gr_hwp_avg], [gr_pdf_w, gr_doc_w, gr_xls_w, gr_hwp_w])\r\n",
    "\r\n",
    "avg_df = pd.DataFrame(list(zip([gr_pdf_avg, gr_doc_avg, gr_xls_avg, gr_hwp_avg],\\\r\n",
    "                                   [gr_pdf_w, gr_doc_w, gr_xls_w, gr_hwp_w])), \\\r\n",
    "                                   columns = ['mean', 'wg_mean'],\\\r\n",
    "                                   index = ['gr_pdf', 'gr_doc', 'gr_xls', 'gr_hwp'])\r\n",
    "\r\n",
    "# 가중치 부여 결과 시각화\r\n",
    "avg_df.plot(kind='barh')\r\n",
    "plt.tight_layout()\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![screenshot](.\\img\\27.png \"27_Sh\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[실습파일](https://github.com/songhunhwa/songhunhwa.github.com/tree/master/tutorial/tutorial_02 \"데이터 분석\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **03-5.리포트 작성**\r\n",
    "------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 분석과정을 마무리 했다면 리포트를 작성하는 과정을 시작한다. 이 과정을 시작하기 전에 분석 초반에 설정한 목적과 가설, 프레임워크를 다시 상기하고 진행하는 것이 유용하다. 리포트는 과정보다는 분석 결과를 중심으로 기술하고, 향후 개선방향과 분석가가 발견한 인사이트를 언급하는 것이 효과적이다.\r\n",
    "\r\n",
    "### 만약 분석 과정에만 큰 비중을 둘 경우 리포트를 제공받는 사람의 집중력과 관심을 잃게될 가능성이 있고, 인사이트나 추후 방향성에 대한 언급이 없으면 어떠한 액션을 취할지 모호해지기 때문이다. 도메인 지식이 부족할지라도 분석가는 최소한 데이터가 의미하는 바를 최대한 발굴하고 개선방향을 다같이 토의할 수 있는 토대는 제공해야 한다. 비록 주관성이 다분하고 틀린 방향일지라도 아무것도 없는 것보다 낫다.\r\n",
    "\r\n",
    "### 이제 가상 케이스에서 분석한 결과를 토대로 리포트를 작성해보자. 만약 분석과정에서 markdown 기능을 활용해 중간에 코멘트를 달아놓으면 리포트 과정에서 도움이 될 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **도입 단계**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 일반적으로 리포트의 도입 단계에는 분석 배경과 목적/가설, 목차 등이 포함된다. 초반에 작성한 내용을 토대로 아래와 같이 간단히 정리할 수 있다.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 배경\r\n",
    "    * ### 기획팀 요청으로 유저의 시나리오 전환이 잘 이루어지고 있는지 파악과 개선이 필요함 \r\n",
    "* ### 목적\r\n",
    "    * ### Funnel 단계별 전환율과 이탈율을 파악해 개선이 필요한 구간(Bottleneck)을 탐색한다.\r\n",
    "    * ### 전환율을 높일 수 있는 실질적인 방안을 찾고 성과를 측정한다.\r\n",
    "* ### 목차\r\n",
    "    * ### 일별 주요 통계\r\n",
    "    * ### 구간별 전환율\r\n",
    "    * ### 클러스터링 결과 및 클러스터별 전환율 차이\r\n",
    "    * ### 전환율 개선을 위한 핵심 Targeting 그룹\r\n",
    "    * ### 시사점 및 개선안"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **본론 단계**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 본론 단계에서는 목차에 맞게 중요도가 높은 결과를 기준으로 기술하며, 만약 일회성(Ad-hoc) 분석이 아닌 Tracking 분석일 경우는 스토리텔링 방식으로 기술하는 것이 효과적이다. (예를 들어, 지난 해와 올해의 주요 지표 변화와 사건/이슈를 같이 첨부하여 기술)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* ### 일별 주요 통계\r\n",
    "\r\n",
    "    * ### 활성화 세션의 경우 주말에 감소하고 주중에 증가하는 트렌드 보임\r\n",
    "    * ### 확장자별 1 tier에는 pdf, xls, doc가 포지셔닝되며, 2 tier에는 hwp, ppt가 포함됨\r\n",
    "    * ### 문서의 이용 위치는 'other app' 이 압도적으로 높음\r\n",
    "    * ### 스크린별로 사용성 파악 결과, 메인(main) 화면이 가장 많이 노출되며 다음 화면(pub_dir or per_dir)으로 넘어가는 경우 많지 않음\r\n",
    "\r\n",
    "* ### 구간별 전환율\r\n",
    "\r\n",
    "    * ### 전환율이 가장 낮은 구간(=이탈이 가장 높은 구간)은 구매정보 페이지에서 구매 완료 페이지로 전환하는 구간임(3.7%)\r\n",
    "    * ###  제품내 웹 -> 앱으로 전환하는 구간은 전환율이 양호함(74%)\r\n",
    "\r\n",
    "* ### 클러스터링\r\n",
    "\r\n",
    "    * ### 전체를 그룹으로 세분화했을 경우 전환율의 차이를 파악하고, 우선순위에 따른 Targeting 위해 k-means 클러스터링 진행함\r\n",
    "    * ### 확장자 변수를 이용하여 아래와 같이 4개의 그룹으로 세분화함\r\n",
    "\r\n",
    "* ### 클러스터 별 전환율 차이\r\n",
    "\r\n",
    "    * ### XLS 그룹: 전반적으로 전환이 유사한 수준으로 진행되나, purchase_page 에서 실 구매로 이어지지 않음\r\n",
    "    * ### DOC 그룹: inproduct_web -> per_dir 으로 전환율은 높으나, per_dir -> purchase_page 구간의 이탈이 두드러짐\r\n",
    "    * ### PDF 그룹: 전반적인 구간에서 전화율이 고르게 낮은 편임. 특히 per_dir -> inproduct_web으로 전환하는 비율이 낮음\r\n",
    "    * ### HWP 그룹: inproduct web -> purchase_page 구간의 이탈이 심한 경향을 보임\r\n",
    "\r\n",
    "* ### 전환율 개선 Target 그룹\r\n",
    "\r\n",
    "    * ### 구간별 가중치를 고려할 경우, 평균 전환율이 가장 낮은 구간은 pdf 사용그룹이므로 개선이 가장 시급한 그룹으로 고려됨\r\n",
    "    * ### XLS 및 DOC 그룹은 상대적으로 양호한 전환율을 보이고 있음. (단, 전환율 상승 지속 노력 필요함)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **결론 단계**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 일반적으로 결론 및 마무리 단계에서는 데이터 분석 결과의 시사점과 한계점, 개선/실행 방안 및 추후 분석 방향 등에 대해 기술한다. 분석가의 주관적 판단과 경험을 토대로 데이터를 통해 얻은 Learning, Insights, 비즈니스적 가치와 문제해결을 위한 아이디어 등에 대해 간결하고 설득력 있게 커뮤니케이션하는 것이 중요하다. 경우에 따라서 결론 및 시사점을 먼저 전달하고 위의 상세한 본론 내용을 뒤에서 제시하는 방식으로 커뮤니케이션을 진행한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **현황**\r\n",
    "\r\n",
    "* ### 주말 대비 주중의 사용성 높음 (세션수 기준)\r\n",
    "* ### doc, pdf, xls 확장자가 주요 항목\r\n",
    "* ### 전체적으로 구매정보 -> 구매결제로 이어지는 전환율이 낮아(3.7%) 개선이 시급함\r\n",
    "* ### 바로 전단계인 제품내 -> 구매정보로의 전환율 역시 낮은 편임(23%)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **시사점**\r\n",
    "* ### 클러스터링 결과 PDF 사용 그룹의 전환율 상대적으로 낮아 원인 파악 필요(24%, 타그룹 평균 약35%)\r\n",
    "* ### 모든 funnel 단계에서 전환율 전반적으로 낮음 (약 20%대)\r\n",
    "* ### 개선 우선순위가 가장 높은(핵심)그룹으로 고려 가능\r\n",
    "* ### PDF 관련 기능 검토 필요 (안정성 등)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **개선 방안**\r\n",
    "* ### 제품 내에서 Right (timing, persons, contents) 제공하여 구매 정보 제고 및 구매 전환 유도\r\n",
    "* ### 디자인/컨텐츠 시안, 타깃 적절히 설계하여 a/b test 진행 후 개선 프로세스 반복\r\n",
    "* ### 관련 신규 부가 기능 검토 및 안정성 확보 필요"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **분석 한계점**\r\n",
    "* ### 클러스터링 방식의 고도화 (보다 세분화된 그룹핑 및 전략 개발)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('AIMath': conda)"
  },
  "interpreter": {
   "hash": "53a6f66994d44a531c15dda9534cca6a0a046d02bce3524de6c1f8e9a8c07fb2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}